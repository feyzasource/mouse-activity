{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef7ecaa-1504-4419-85a1-021fc4dd012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam Gerçek Dosya: 10\n",
      "Toplam Sahte Dosya: 1675\n",
      "Seçilen özellikler: ['x_direction_changes', 'y_direction_changes', 'min_y', 'max_x', 'max_y', 'avg_speed', 'mouse_idle_ratio', 'movement_entropy']\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[180900      0]\n",
      " [     7 180265]]\n",
      "Accuracy   : 1.0000\n",
      "Precision  : 1.0000\n",
      "Recall     : 1.0000\n",
      "Specificity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# ----------------------\n",
    "# Verilerin Yolu\n",
    "# ----------------------\n",
    "REAL_DIR = r\"C:/store/git/km-stat-activity/data/real\"\n",
    "FAKE_DIR = r\"C:/store/git/km-stat-activity/processed/fake\"\n",
    "\n",
    "# Real dosyalar: km_stat_1_processed.csv .. km_stat_10_processed.csv\n",
    "real_files = sorted(glob.glob(os.path.join(REAL_DIR, \"km_stat_*_processed.csv\")))\n",
    "\n",
    "# Fake dosyalar: profile_guid=*/*-processed.csv\n",
    "fake_files = sorted(glob.glob(os.path.join(FAKE_DIR, \"profile_guid=*\", \"*-processed.csv\")))\n",
    "\n",
    "print(f\"Toplam Gerçek Dosya: {len(real_files)}\")\n",
    "print(f\"Toplam Sahte Dosya: {len(fake_files)}\")\n",
    "\n",
    "# ----------------------\n",
    "# Dosyaları oku ve etiketle\n",
    "# ----------------------\n",
    "def load_and_label(files, label):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        df['label'] = label\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "real_df = load_and_label(real_files, 1)\n",
    "fake_df = load_and_label(fake_files, 0)\n",
    "\n",
    "# ----------------------\n",
    "# Tüm veriyi birleştir\n",
    "# ----------------------\n",
    "df_all = pd.concat([real_df, fake_df], ignore_index=True)\n",
    "\n",
    "# ----------------------\n",
    "# Öznitelik Seçimi \n",
    "# ----------------------\n",
    "FEATURE_COLUMNS = [\n",
    "    'x_direction_changes', 'y_direction_changes',\n",
    "    'min_x', 'min_y', 'max_x', 'max_y',\n",
    "    'bbox_area', 'avg_speed', 'avg_acceleration',\n",
    "    'mouse_idle_ratio', 'movement_entropy', 'linearity'\n",
    "]\n",
    "\n",
    "\n",
    "X = df_all[FEATURE_COLUMNS]\n",
    "y = df_all['label']\n",
    "\n",
    "# ----------------------\n",
    "# Train-Test ayırma\n",
    "# ----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# StandardScaler (Z-Score)\n",
    "# ----------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------\n",
    "# SelectKBest ile en iyi 8 özelliği seç\n",
    "# ----------------------\n",
    "k_best = SelectKBest(score_func=f_classif, k=8)\n",
    "X_train_k = k_best.fit_transform(X_train_scaled, y_train)\n",
    "X_test_k = k_best.transform(X_test_scaled)\n",
    "selected_features = [FEATURE_COLUMNS[i] for i in k_best.get_support(indices=True)]\n",
    "print(\"Seçilen özellikler:\", selected_features)\n",
    "\n",
    "# -önce bu kodu çalıştırayım değil mi---------------------\n",
    "# Logistic Regression\n",
    "# ----------------------\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "model_lr.fit(X_train_k, y_train)\n",
    "y_pred = model_lr.predict(X_test_k)\n",
    "\n",
    "# ----------------------\n",
    "# Değerlendirme\n",
    "# ----------------------\n",
    "cm_lr = confusion_matrix(y_test, y_pred)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "precision_lr = precision_score(y_test, y_pred)\n",
    "recall_lr = recall_score(y_test, y_pred)\n",
    "specificity_lr = cm_lr[0,0] / (cm_lr[0,0] + cm_lr[0,1])\n",
    "\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", cm_lr)\n",
    "print(f\"Accuracy   : {accuracy_lr:.4f}\")\n",
    "print(f\"Precision  : {precision_lr:.4f}\")\n",
    "print(f\"Recall     : {recall_lr:.4f}\")\n",
    "print(f\"Specificity: {specificity_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4af139-a180-4f9d-b8c5-58766a26fb35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-demo",
   "language": "python",
   "name": "ai-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
