{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10f30e51",
   "metadata": {},
   "source": [
    "# Load and Concatenate Multi-Day Data\n",
    "This notebook shows how to load multiple CSV files (one per day),\n",
    "concatenate them into a single DataFrame, and then apply the same time-segment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079feb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# 1) Directory containing your daily CSVs\n",
    "data_dir = Path(r\"C:\\store\\git\\km-stat-activity\\data\\real\")\n",
    "\n",
    "# 2) Gather all CSV files (adjust pattern if needed)\n",
    "csv_files = sorted(data_dir.glob(\"*.csv\"))\n",
    "print(\"Found CSV files:\", [f.name for f in csv_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d068652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Read and parse each CSV, adding DataFrame to list\n",
    "dfs = []\n",
    "for csv in csv_files:\n",
    "    df_day = pd.read_csv(\n",
    "        csv,\n",
    "        converters={\"x\": lambda s: ast.literal_eval(s) if isinstance(s, str) else [], \n",
    "                    \"y\": lambda s: ast.literal_eval(s) if isinstance(s, str) else []},\n",
    "        parse_dates=[\"start_date_time\", \"end_date_time\"]\n",
    "    )\n",
    "    # If 'date' column is missing or as string, convert to datetime.date\n",
    "    if 'date' in df_day.columns and df_day['date'].dtype == object:\n",
    "        df_day['date'] = pd.to_datetime(df_day['date']).dt.date\n",
    "    # Or infer date from filename: e.g. '2025-04-14_...'\n",
    "    else:\n",
    "        date_from_name = csv.stem.split('_')[0]\n",
    "        df_day['date'] = pd.to_datetime(date_from_name).date()\n",
    "    dfs.append(df_day)\n",
    "\n",
    "# 4) Concatenate all days\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Combined DataFrame shape: {df_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e19a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Define time segments (as before)\n",
    "def time_segment(ts):\n",
    "    h = ts.hour + ts.minute/60\n",
    "    if 8.5  <= h < 10:    return \"morning_start\"\n",
    "    if 11   <= h < 12.5:  return \"pre_lunch\"\n",
    "    if 13.5 <= h < 15.5:  return \"post_lunch\"\n",
    "    if 15.5 <= h < 17:    return \"afternoon_peak\"\n",
    "    if 17   <= h < 17.5:  return \"end_of_day\"\n",
    "    return \"other\"\n",
    "\n",
    "df_all['segment'] = df_all['start_date_time'].map(time_segment)\n",
    "print(\"Segments assigned, unique:\", df_all['segment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a743042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Example: summarizing avg_speed for user over all days\n",
    "user = \"013d5cac-f09d-48a5-bff1-00d81c91b017\"  # replace as needed\n",
    "df_user = df_all[df_all['profile_guid'] == user]\n",
    "summary_all = df_user.groupby(['date','segment'])['avg_speed'].mean().reset_index()\n",
    "summary_all"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
